1. Interpretation of Sort Merge Join
   First, the edges from the given database are classified into three groups according to their labels. The groups of edges are stored as three new databases.

   Then, we iterate every edge in the first group and the second group to store the edges from the second group that satisfy firstEdge.to = secondEdge.from into a new database. The process is achieved in the *connectEdges function. We firstly sort the left edges by 'to' values and the second edges by 'from' values in ascending order. We implement our own quick sort function, which can be check at quickSort. Because the join attributes are not unique here, we loop every left edge that has a 'to' value that equals the 'from' value of current right edges.

   We store the count of matching in the max_size of the new result database, and also the edges of matching from the second edges group. We repeat the above step with the previous result and the third edge group to get the new database. The final result will be the max_size of the database.



2. Interpretation of Hash Join
    We use the struct Edge_tuple above and a struct HashJoinTable for the Hash join method. HashJoinTable contains
    a list of Edge_tuple called 'edges', a int for its size, and a unsigned long for its maximum allocation size.

    At the insertion stage, an Edge_tuple is allocated and assigned with the attributes values input.
    At the edge delete stage, the target edge in 'edges' for deletion is marked as deleted, but it still occupies
    memory space, and this part of memory will be freed when the whole dataset is deleted.

    Run Query:
    By hashing and probing for 3 times in total (between edges group 1 vs 2, 2 vs 3 and 3 vs 1) we finally locate
    the triangles. Finally, the counts of the number of triangles are returned.

3. Analyse the performance
In the performance report, Sort Merge Join method can run the iteration under 64, 128, 256, 512 KiB is approx. 2600,
860, 250 and 60 respectively, while the Hash Join method can only reach approx. 1870 530, 150 and 40. The Sort Merge
Join in obviously faster than the Hash Join method under dataset in this test.

Generally speaking,sort merge joins are faster and uses less memory than hash joins. The sort join has a complexity of
O(n^2) + O(m^2) + O(m*n) in the worst case, where n is the size of the left relation and m is the size of the right
relation. The previous O(n^2) + O(m^2) are the complexity of the quick sort process and the O(m*n) is the merge
process. Because the index increases once the matching is found, every tuple in the right relation only goes through
once. In the worst case, every tuples in the right relation goes through the whole left relation. Hence,O(m+n) in
the worst case.

Theoretically, hash join can be very fast for small dataset, but in this coursework, the data can be sorted easily in
the process of query, so the actual run time of sort merge join is faster.
